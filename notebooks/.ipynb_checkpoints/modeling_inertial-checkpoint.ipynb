{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/renjie/Documents/MTech/AY1819Sem1/KE5208_SenseMakingAndInsightsDiscovery/CA'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(os.path.join(os.getcwd(), '..'))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renjie/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from src.utils import get_dataset\n",
    "from src.utils import select_data\n",
    "\n",
    "import scipy.io as sio\n",
    "from scipy.signal import resample\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import UpSampling1D\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(os.getcwd(), 'data')\n",
    "os.listdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_path, _,inertial_path, skeleton_path,rgb_path = get_dataset(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = list(range(1,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_subject(d_path, subject):\n",
    "    select_statement = '_s{}_'.format(subject)\n",
    "    subjects = []\n",
    "    for i in d_path:\n",
    "        if select_statement in i:\n",
    "            subjects.append(i)\n",
    "    return subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_number(single_path):\n",
    "    return int(single_path.split('/')[-1].split('_')[0][1:])\n",
    "def get_subject_number(single_path):\n",
    "    return int(single_path.split('/')[-1].split('_')[1][1:])\n",
    "def get_trial_number(single_path):\n",
    "    return int(single_path.split('/')[-1].split('_')[2][1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_len_inertial(inertial_d):\n",
    "    inertial_d = np.swapaxes(inertial_d, 0,1)\n",
    "    inertial_d = sequence.pad_sequences(inertial_d, maxlen=326)\n",
    "    inertial_d = np.swapaxes(inertial_d, 0,1)\n",
    "    return inertial_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on subject 1,3,5,7\n",
    "# test on subject 2,4,6,8\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "resample_len = 180\n",
    "\n",
    "for path in inertial_path:\n",
    "    if get_subject_number(path) in [1,3,5,7]:\n",
    "        X_train.append(path)\n",
    "        Y_train.append(get_action_number(path))\n",
    "    else:\n",
    "        X_test.append(path)\n",
    "        Y_test.append(get_action_number(path))\n",
    "\n",
    "# X_train = [pad_len_inertial(sio.loadmat(x)['d_iner']) for x in X_train]\n",
    "# X_test = [pad_len_inertial(sio.loadmat(x)['d_iner']) for x in X_test]\n",
    "\n",
    "X_train = [resample(sio.loadmat(x)['d_iner'], resample_len) for x in X_train]\n",
    "X_test = [resample(sio.loadmat(x)['d_iner'], resample_len) for x in X_test]\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "Y_train = to_categorical(np.array(Y_train) - 1)\n",
    "Y_test = to_categorical(np.array(Y_test) - 1)\n",
    "\n",
    "##################\n",
    "# normalize data #\n",
    "##################\n",
    "\n",
    "# X_train[:,:,3:] = X_train[:,:,3:]/ max(X_train[:,:,3:].max(), abs(X_train[:,:,3:].min()))\n",
    "# X_train[:,:,:3] = X_train[:,:,:3]/ max(X_train[:,:,:3].max(), abs(X_train[:,:,:3].min()))\n",
    "\n",
    "# X_test[:,:,3:] = X_test[:,:,3:]/ max(X_test[:,:,3:].max(), abs(X_test[:,:,3:].min()))\n",
    "# X_test[:,:,:3] = X_test[:,:,:3]/ max(X_test[:,:,:3].max(), abs(X_test[:,:,:3].min()))\n",
    "\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    '''\n",
    "    Calculates the F1 by using keras.backend\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "#     print(\"precision: \", precision)\n",
    "#     print(\"recall: \", recall)\n",
    "    return 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_LSTM():\n",
    "    np.random.seed(7)\n",
    "    model = Sequential(name = 'simple_LSTM')\n",
    "    model.add(LSTM(512, input_shape=(None, 6), recurrent_dropout=0.5))\n",
    "    model.add(Dense(len(activities), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy', 'mse',f1])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidirectional_LSTM():\n",
    "    np.random.seed(7)\n",
    "    model = Sequential(name = 'bidirectional_LSTM')\n",
    "    model.add(Bidirectional(LSTM(50), input_shape=(None, 6)), recurrent_dropout=0.5)\n",
    "    model.add(Dense(len(activities), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3), metrics=['accuracy', 'mse',f1])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_LSTM():\n",
    "    # Create the model\n",
    "    np.random.seed(7)\n",
    "    optimizer = Adam(lr=1e-4, decay=1e-6, clipnorm=0.6)\n",
    "    model = Sequential(name = 'conv_LSTM')\n",
    "    model.add(Conv1D(128,\n",
    "                     4,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1,\n",
    "                    input_shape=(180, 6)))\n",
    "    model.add(Conv1D(64,\n",
    "                     4,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    #model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64,\n",
    "                     4,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(Conv1D(64,\n",
    "                     4,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(LSTM(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(LSTM(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(len(activities), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_LSTM2():\n",
    "    # Create the model\n",
    "    np.random.seed(7)\n",
    "    optimizer = Adam(lr=1e-4)\n",
    "    model = Sequential(name = 'conv_LSTM2')\n",
    "    model.add(Conv1D(16,\n",
    "                     3,\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     strides=1,\n",
    "                     kernel_initializer = 'glorot_uniform',\n",
    "                    input_shape=(180, 6)))\n",
    "    model.add(Conv1D(32,\n",
    "                     3,\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     strides=1,\n",
    "                    kernel_initializer = 'glorot_uniform'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     strides=1,\n",
    "                    kernel_initializer = 'glorot_uniform'))\n",
    "    model.add(Conv1D(128,\n",
    "                     3,\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     strides=1,\n",
    "                    kernel_initializer = 'glorot_uniform'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(LSTM(256, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "    model.add(LSTM(512, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(activities), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet_LSTM():\n",
    "    optimizer = Adam(lr=1e-4)\n",
    "    inputs = Input((180, 6))\n",
    "  \n",
    "  # encoding phase\n",
    "    conv1 = Conv1D(32,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(inputs)\n",
    "    conv2 = Conv1D(32,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size = 2)(conv2) # 90\n",
    "\n",
    "    conv3 = Conv1D(64,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(pool1)\n",
    "    conv4 = Conv1D(64,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(conv3)\n",
    "    pool2 = MaxPooling1D(pool_size = 2)(conv4) # 45\n",
    "\n",
    "    #   conv5 = Conv1D(128,\n",
    "    #                  3,\n",
    "    #                  padding='same',\n",
    "    #                  activation='relu',\n",
    "    #                  strides=1,\n",
    "    #                  kernel_initializer = 'glorot_uniform')(pool2)\n",
    "    #   conv6 = Conv1D(128,\n",
    "    #                  3,\n",
    "    #                  padding='same',\n",
    "    #                  activation='relu',\n",
    "    #                  strides=1,\n",
    "    #                  kernel_initializer = 'glorot_uniform')(conv5)\n",
    "    #   pool3 = MaxPooling1D(pool_size = 2)(conv6) # \n",
    "\n",
    "    # middle phase\n",
    "    conv7 = Conv1D(128,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(pool2)\n",
    "    conv8 = Conv1D(128,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(conv7)\n",
    "    drop1 = Dropout(0.5)(conv8)\n",
    "\n",
    "    # decoding phase\n",
    "    #   up1 = Conv1D(128,\n",
    "    #                  2,\n",
    "    #                  padding='same',\n",
    "    #                  activation='relu',\n",
    "    #                  strides=1,\n",
    "    #                  kernel_initializer = 'glorot_uniform')(UpSampling1D(size = 2)(drop1))\n",
    "    #   concat1 = Concatenate(axis=-1)([conv6, up1])\n",
    "    #   conv9 = Conv1D(128,\n",
    "    #                  3,\n",
    "    #                  padding='same',\n",
    "    #                  activation='relu',\n",
    "    #                  strides=1,\n",
    "    #                  kernel_initializer = 'glorot_uniform')(UpSampling1D(size = 2)(concat1))\n",
    "    #   conv10 = Conv1D(128,\n",
    "    #                  3,\n",
    "    #                  padding='same',\n",
    "    #                  activation='relu',\n",
    "    #                  strides=1,\n",
    "    #                  kernel_initializer = 'glorot_uniform')(UpSampling1D(size = 2)(conv9))\n",
    "\n",
    "    up2 = Conv1D(64,\n",
    "               2,\n",
    "               padding='same',\n",
    "               activation='relu',\n",
    "               strides=1,\n",
    "               kernel_initializer = 'glorot_uniform')(UpSampling1D(size = 2)(drop1))\n",
    "    concat2 = Concatenate(axis=-1)([conv4, up2])\n",
    "    conv11 = Conv1D(64,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(concat2)\n",
    "    conv12 = Conv1D(64,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(conv11)\n",
    "\n",
    "    up3 = Conv1D(32,\n",
    "               2,\n",
    "               padding='same',\n",
    "               activation='relu',\n",
    "               strides=1,\n",
    "               kernel_initializer = 'glorot_uniform')(UpSampling1D(size = 2)(conv12))\n",
    "    concat3 = Concatenate(axis=-1)([conv2, up3])\n",
    "    conv13 = Conv1D(32,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(concat3)\n",
    "    conv14 = Conv1D(128,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(conv13)\n",
    "\n",
    "    # classification Level\n",
    "    lstm1 = LSTM(256, return_sequences=True, dropout=0.5, recurrent_dropout=0.5)(conv14)\n",
    "    lstm2 = LSTM(512, return_sequences=True, dropout=0.5, recurrent_dropout=0.5)(lstm1)\n",
    "    flat1 = Flatten()(lstm2)\n",
    "\n",
    "    dense1 = Dense(len(activities), activation='softmax')(flat1)\n",
    "\n",
    "    model = Model(input = inputs, output = dense1, name = 'UNet_LSTM')\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'recurrent_dropout')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bebf8d02fa16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model = simple_LSTM()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbidirectional_LSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# model = conv_LSTM()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# model = UNet_LSTM()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b54ae528f1b1>\u001b[0m in \u001b[0;36mbidirectional_LSTM\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bidirectional_LSTM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer, merge_mode, weights, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_masking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_constants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# to the inputs to the Wrapper layer).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Keyword argument not understood:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'recurrent_dropout')"
     ]
    }
   ],
   "source": [
    "# model = simple_LSTM()\n",
    "model = bidirectional_LSTM()\n",
    "# model = conv_LSTM()\n",
    "# model = UNet_LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = os.path.join(os.getcwd(), 'logs')\n",
    "tb = TensorBoard(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = 'weights/' + model.name + \\\n",
    "            '-{epoch:02d}-{loss:.2f}.hdf5'\n",
    "chkpt = ModelCheckpoint(filepath=weights_dir, monitor='loss', save_best_only=True, save_weights_only=True, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=20, batch_size=3, validation_data = (X_test, Y_test), callbacks=[tb, chkpt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(train_acc, 'C0')\n",
    "plt.plot(val_acc, 'C1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history.history['loss']\n",
    "val_acc = history.history['val_loss']\n",
    "plt.plot(train_acc, 'C0')\n",
    "plt.plot(val_acc, 'C1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = np.argmax(model.predict(X_test), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['swipe to the left',\n",
    "               'swipe to the right',\n",
    "               'wave',\n",
    "               'front clap',\n",
    "               'throw',\n",
    "               'cross arms',\n",
    "               'basketball shoot',\n",
    "               'draw x',\n",
    "               'draw circle (CW)',\n",
    "               'draw circle (CCW)',\n",
    "               'draw triangle',\n",
    "               'bowling',\n",
    "               'boxing',\n",
    "               'baseball swing',\n",
    "               'tennis swing',\n",
    "               'arm curl',\n",
    "               'tennis serve',\n",
    "               'two hand push',\n",
    "               'knock door',\n",
    "               'catch',\n",
    "               'pick and throw',\n",
    "               'jogging',\n",
    "               'walking',\n",
    "               'sit to stand',\n",
    "               'stand to sit',\n",
    "               'forward lunge',\n",
    "               'squat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_1 = confusion_matrix(np.argmax(Y_test, axis = -1), pred_1)\n",
    "NUM_LABELS = 27\n",
    "\n",
    "f, axes = plt.subplots(1,1, figsize = (12,12))\n",
    "axes.set_xlabel('Actual')\n",
    "axes.set_ylabel('Predicted')\n",
    "axes.grid(False)\n",
    "axes.set_xticklabels(class_labels, rotation = 90)\n",
    "axes.set_yticklabels(class_labels)\n",
    "axes.set_yticks(list(range(27)))\n",
    "axes.set_xticks(list(range(27)))\n",
    "plt.imshow(confusion_1, cmap=plt.cm.Set2, interpolation='nearest')\n",
    "\n",
    "for i, cas in enumerate(confusion_1):\n",
    "    for j, count in enumerate(cas):\n",
    "        if count > 0:\n",
    "            xoff = .07 * len(str(count))\n",
    "            plt.text(j-xoff, i+.2, int(count), fontsize=12, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeing if there is a bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(inertial_path)):\n",
    "    test = sio.loadmat(inertial_path[i])['d_iner']\n",
    "    test = np.expand_dims(np.swapaxes(sequence.pad_sequences(np.swapaxes(test,1,0), maxlen= 326), 1, 0), axis =0)\n",
    "    pred = model.predict(test)\n",
    "    print('Predicted: {} Expected: [{}]'.format(np.argmax(pred, axis = -1) + 1, get_action_number(inertial_path[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sio.loadmat(inertial_path[num])['d_iner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.expand_dims(np.swapaxes(sequence.pad_sequences(np.swapaxes(test,1,0), maxlen= 326), 1, 0), axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(pred, axis = -1), inertial_path[num].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
